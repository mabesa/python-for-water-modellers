{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Module 4b: Your First Water Modelling Script\n",
    "## Analyzing Real Discharge Data\n",
    "\n",
    "**Time required:** 40-50 minutes  \n",
    "**Prerequisites:** Module 4a (data downloaded)  \n",
    "**What you'll do:** Load, analyze, and visualize real hydrological data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## What We'll Build\n",
    "\n",
    "In this module, you'll analyze the discharge data you downloaded in Module 4a. We'll:\n",
    "\n",
    "1. **Load** discharge data from the CSV file\n",
    "2. **Check** data quality (missing values, date ranges)\n",
    "3. **Calculate** hydrological statistics (mean, percentiles, monthly values)\n",
    "4. **Identify** high and low flow events\n",
    "5. **Create** professional hydrograph plots\n",
    "6. **Generate** monthly distribution analysis\n",
    "7. **Build** a flow duration curve (FDC)\n",
    "\n",
    "This is real water modelling workâ€”the kind of analysis you might do for a project or report.\n",
    "\n",
    "### The Data\n",
    "\n",
    "We'll use the CAMELS streamflow data you downloaded in Module 4a. The CSV file is in your `data/` folder and contains:\n",
    "- Daily discharge values in mÂ³/s\n",
    "- Station metadata (ID and name)\n",
    "- Date information for time series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## Step 1: Check Your Data\n",
    "\n",
    "Before we start the analysis, let's verify you have the data from Module 4a.\n",
    "\n",
    "Your project should have:\n",
    "- A `data/` folder with a CSV file like `camels_01013500_discharge.csv`\n",
    "- The file contains columns: `date`, `discharge_m3s`, `discharge_mm_day`, `station_id`, `station_name`\n",
    "\n",
    "Let's check what files we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ddcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the path helper we created in Module 4a\n",
    "# This is saved in src/python_for_water_modellers/paths.py for reuse\n",
    "from python_for_water_modellers import get_data_path\n",
    "\n",
    "DATA_PATH = get_data_path()\n",
    "\n",
    "# List available data files\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Data path exists: {DATA_PATH.exists()}\")\n",
    "if DATA_PATH.exists():\n",
    "    data_files = [f.name for f in DATA_PATH.glob('*.csv')]\n",
    "    print(\"CSV files in data/ folder:\")\n",
    "    for f in data_files:\n",
    "        print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2918d4ed",
   "metadata": {},
   "source": [
    "You should see your downloaded CAMELS file listed. Note the filenameâ€”you'll need it in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore Your Data\n",
    "\n",
    "Let's start by loading the data and seeing what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Update with your filename from Step 1\n",
    "STATION_ID = '01013500'  # Change to your station ID\n",
    "INPUT_FILE = DATA_PATH / f'camels_{STATION_ID}_discharge.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Loading discharge data...\")\n",
    "print()\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"File: {INPUT_FILE}\")\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print()\n",
    "print(\"First few rows:\")\n",
    "print(df.head())\n",
    "print()\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "**What to check:**\n",
    "- Do you see the expected columns (`date`, `discharge_m3s`, etc.)?\n",
    "- Is the date column recognized as text (object) for now? We'll convert it next.\n",
    "- Does the data look reasonable?\n",
    "\n",
    "If everything looks good, let's continue with the full analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "## Step 3: Complete Discharge Analysis\n",
    "\n",
    "Now let's perform a complete discharge analysis. We'll break it into logical sections that you can run sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "### Part 1: Prepare the Data for Analysis\n",
    "\n",
    "Convert dates and set up the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATE_COLUMN = 'date'\n",
    "DISCHARGE_COLUMN = 'discharge_m3s'\n",
    "\n",
    "print(\"Preparing data for analysis...\")\n",
    "print()\n",
    "\n",
    "# Convert date column to datetime format\n",
    "df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN])\n",
    "\n",
    "# Set date as the index for time-series operations\n",
    "df = df.set_index(DATE_COLUMN)\n",
    "\n",
    "# Get station name from the data\n",
    "station_name = df['station_name'].iloc[0] if 'station_name' in df.columns else \"Unknown Station\"\n",
    "\n",
    "# Report what we have\n",
    "print(f\"Station: {station_name}\")\n",
    "print(f\"Period: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Total records: {len(df)} days\")\n",
    "\n",
    "# Check for missing data\n",
    "missing_count = df[DISCHARGE_COLUMN].isna().sum()\n",
    "if missing_count > 0:\n",
    "    missing_pct = missing_count / len(df) * 100\n",
    "    print(f\"Missing data: {missing_count} days ({missing_pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"No missing data\")\n",
    "print()\n",
    "print(\"âœ“ Data prepared and ready for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Why set the date as index?** This enables powerful time-series features like automatic date formatting on plots, easy resampling (daily â†’ monthly), and simple date range selection: `df['2022-06':'2022-08']`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "### Part 2: Calculate Flow Statistics\n",
    "\n",
    "Now let's calculate key hydrological statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE FLOW STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Calculating statistics...\")\n",
    "\n",
    "# Get discharge series, excluding missing values\n",
    "Q = df[DISCHARGE_COLUMN].dropna()\n",
    "\n",
    "# Calculate key statistics\n",
    "# Note: Q10/Q90 use exceedance probability convention\n",
    "# Q10 = flow exceeded 10% of time (high flow)\n",
    "# Q90 = flow exceeded 90% of time (low flow)\n",
    "stats = {\n",
    "    'Mean discharge (mÂ³/s)': Q.mean(),\n",
    "    'Median discharge (mÂ³/s)': Q.median(),\n",
    "    'Standard deviation (mÂ³/s)': Q.std(),\n",
    "    'Minimum (mÂ³/s)': Q.min(),\n",
    "    'Maximum (mÂ³/s)': Q.max(),\n",
    "    'Q90 - Low flow threshold (mÂ³/s)': Q.quantile(0.10),   # Exceeded 90% of time\n",
    "    'Q10 - High flow threshold (mÂ³/s)': Q.quantile(0.90),  # Exceeded 10% of time\n",
    "}\n",
    "\n",
    "print()\n",
    "print(\"FLOW STATISTICS\")\n",
    "print(\"-\" * 45)\n",
    "for name, value in stats.items():\n",
    "    print(f\"  {name:<35} {value:>8.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "> **What are Q10 and Q90?**\n",
    ">\n",
    "> These are flow thresholds commonly used in hydrology, named by exceedance probability:\n",
    "> - **Q10**: Flow exceeded only 10% of the time (high flow indicator)\n",
    "> - **Q90**: Flow exceeded 90% of the time (low flow indicator)\n",
    ">\n",
    "> This tutorial uses the **exceedance probability convention** throughout, which is standard in water resources engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "### Part 3: Identify Extreme Events\n",
    "\n",
    "Find high and low flow periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IDENTIFY EXTREME EVENTS\n",
    "# =============================================================================\n",
    "\n",
    "# Define thresholds using percentiles\n",
    "threshold_high = Q.quantile(0.90)\n",
    "threshold_low = Q.quantile(0.10)\n",
    "\n",
    "# Find days exceeding thresholds\n",
    "high_flow_days = df[df[DISCHARGE_COLUMN] > threshold_high]\n",
    "low_flow_days = df[df[DISCHARGE_COLUMN] < threshold_low]\n",
    "\n",
    "print(\"EXTREME EVENTS\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# High flow summary\n",
    "print(f\"  High flow events (Q > {threshold_high:.1f} mÂ³/s):\")\n",
    "print(f\"    {len(high_flow_days)} days identified\")\n",
    "if len(high_flow_days) > 0:\n",
    "    max_day = Q.idxmax()\n",
    "    max_value = Q.max()\n",
    "    print(f\"    Maximum: {max_value:.1f} mÂ³/s on {max_day.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Low flow summary\n",
    "print(f\"  Low flow events (Q < {threshold_low:.1f} mÂ³/s):\")\n",
    "print(f\"    {len(low_flow_days)} days identified\")\n",
    "if len(low_flow_days) > 0:\n",
    "    min_day = Q.idxmin()\n",
    "    min_value = Q.min()\n",
    "    print(f\"    Minimum: {min_value:.1f} mÂ³/s on {min_day.strftime('%Y-%m-%d')}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2",
   "metadata": {},
   "source": [
    "### Part 4: Monthly Summary\n",
    "\n",
    "Calculate monthly statistics to see seasonal patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MONTHLY SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "# Resample to monthly and calculate statistics\n",
    "# 'ME' means month end frequency\n",
    "monthly = df[DISCHARGE_COLUMN].resample('ME').agg(['mean', 'min', 'max', 'std'])\n",
    "monthly.columns = ['Mean', 'Min', 'Max', 'Std']\n",
    "\n",
    "# Format the index for display\n",
    "monthly.index = monthly.index.strftime('%Y-%m')\n",
    "\n",
    "print(\"MONTHLY SUMMARY (mÂ³/s)\")\n",
    "print(\"-\" * 55)\n",
    "print(monthly.round(1).to_string())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "### Part 5: Create Visualizations\n",
    "\n",
    "Finally, let's create professional plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE VISUALIZATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Creating visualizations...\")\n",
    "\n",
    "# Create a figure with 2 subplots stacked vertically\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# --- Plot 1: Hydrograph ---\n",
    "ax1 = axes[0]\n",
    "\n",
    "# Plot the discharge time series\n",
    "ax1.plot(df.index, df[DISCHARGE_COLUMN], 'b-', linewidth=0.8, label='Daily discharge')\n",
    "\n",
    "# Add mean line\n",
    "mean_q = stats['Mean discharge (mÂ³/s)']\n",
    "ax1.axhline(y=mean_q, color='red', linestyle='--', linewidth=1.5,\n",
    "            label=f'Mean ({mean_q:.1f} mÂ³/s)')\n",
    "\n",
    "# Add shading under the curve\n",
    "ax1.fill_between(df.index, 0, df[DISCHARGE_COLUMN], alpha=0.3)\n",
    "\n",
    "# Mark high flow events\n",
    "ax1.scatter(high_flow_days.index, high_flow_days[DISCHARGE_COLUMN],\n",
    "            color='red', s=20, zorder=5, label='High flow events')\n",
    "\n",
    "# Labels and formatting\n",
    "ax1.set_ylabel('Discharge (mÂ³/s)')\n",
    "ax1.set_title(f'{station_name} - Daily Discharge Hydrograph')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 2: Monthly Box Plot ---\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Prepare data for box plot (group by month)\n",
    "df_temp = df.copy()\n",
    "df_temp['month'] = df_temp.index.month\n",
    "\n",
    "# Create box plot data for each month\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "box_data = [df_temp[df_temp['month'] == m][DISCHARGE_COLUMN].dropna().values\n",
    "            for m in range(1, 13)]\n",
    "\n",
    "# Create the box plot (use tick_labels instead of deprecated labels)\n",
    "bp = ax2.boxplot(box_data, tick_labels=month_names, patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "\n",
    "# Labels and formatting\n",
    "ax2.set_ylabel('Discharge (mÂ³/s)')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_title('Monthly Discharge Distribution')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Analysis complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5b6c7",
   "metadata": {},
   "source": [
    "## Understanding the Code\n",
    "\n",
    "Let's review the key Python concepts used:\n",
    "\n",
    "| Code | What It Does |\n",
    "|------|-------------|\n",
    "| `pd.read_csv(file)` | Loads a CSV file into a DataFrame |\n",
    "| `pd.to_datetime(column)` | Converts text to date format |\n",
    "| `df.set_index(column)` | Sets a column as row labels |\n",
    "| `series.mean()`, `.max()`, `.min()` | Calculate statistics |\n",
    "| `series.quantile(0.90)` | Find the 90th percentile |\n",
    "| `df.resample('ME')` | Group data by month |\n",
    "| `plt.subplots(2, 1)` | Create a figure with 2 plots |\n",
    "| `ax.plot(x, y)` | Draw a line plot |\n",
    "| `ax.boxplot(data)` | Create a box plot |\n",
    "\n",
    "### Key Design Patterns\n",
    "\n",
    "**1. Configuration at the top**\n",
    "```python\n",
    "INPUT_FILE = 'data.csv'\n",
    "DISCHARGE_COLUMN = 'discharge_m3s'\n",
    "```\n",
    "Makes adapting the script easyâ€”change settings in one place.\n",
    "\n",
    "**2. Handling missing data**\n",
    "```python\n",
    "Q = df[DISCHARGE_COLUMN].dropna()\n",
    "```\n",
    "Always check for and handle missing values before calculations.\n",
    "\n",
    "**3. Clear section headers**\n",
    "```python\n",
    "# =============================================================================\n",
    "# CALCULATE STATISTICS\n",
    "# =============================================================================\n",
    "```\n",
    "Makes the code easy to navigate and understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6c7d8",
   "metadata": {},
   "source": [
    "## Adapting for Your Own Data\n",
    "\n",
    "To use this script with your own discharge data:\n",
    "\n",
    "### 1. Check Your Data Format\n",
    "\n",
    "Your CSV should have at least:\n",
    "- A date column (any reasonable format)\n",
    "- A discharge column (numeric values)\n",
    "\n",
    "### 2. Update the Configuration\n",
    "\n",
    "```python\n",
    "INPUT_FILE = 'your_data.csv'\n",
    "DATE_COLUMN = 'your_date_column_name'\n",
    "DISCHARGE_COLUMN = 'your_discharge_column_name'\n",
    "STATION_NAME = 'Your Station Name'\n",
    "```\n",
    "\n",
    "### 3. Handle Different Date Formats\n",
    "\n",
    "If your dates are in a specific format (e.g., European `DD.MM.YYYY`):\n",
    "\n",
    "```python\n",
    "df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN], format='%d.%m.%Y')\n",
    "```\n",
    "\n",
    "Common format codes:\n",
    "- `%Y-%m-%d` â†’ 2024-01-15\n",
    "- `%d.%m.%Y` â†’ 15.01.2024\n",
    "- `%d/%m/%Y` â†’ 15/01/2024\n",
    "- `%m/%d/%Y` â†’ 01/15/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7d8e9",
   "metadata": {},
   "source": [
    "## Common Issues with Real Data\n",
    "\n",
    "Real hydrological data often has issues. Here's how to handle them:\n",
    "\n",
    "### Missing Values\n",
    "\n",
    "```python\n",
    "# Check how much is missing\n",
    "missing_pct = df[DISCHARGE_COLUMN].isna().sum() / len(df) * 100\n",
    "print(f\"Missing: {missing_pct:.1f}%\")\n",
    "\n",
    "# Option 1: Drop missing values (what we did)\n",
    "Q = df[DISCHARGE_COLUMN].dropna()\n",
    "\n",
    "# Option 2: Interpolate small gaps\n",
    "df[DISCHARGE_COLUMN] = df[DISCHARGE_COLUMN].interpolate(method='time')\n",
    "```\n",
    "\n",
    "### Outliers\n",
    "\n",
    "```python\n",
    "# Flag potential outliers (values beyond 3 standard deviations)\n",
    "mean_q = df[DISCHARGE_COLUMN].mean()\n",
    "std_q = df[DISCHARGE_COLUMN].std()\n",
    "outliers = df[abs(df[DISCHARGE_COLUMN] - mean_q) > 3 * std_q]\n",
    "print(f\"Potential outliers: {len(outliers)} days\")\n",
    "```\n",
    "\n",
    "### Negative Values\n",
    "\n",
    "```python\n",
    "# Check for invalid negative discharge\n",
    "negative = df[df[DISCHARGE_COLUMN] < 0]\n",
    "if len(negative) > 0:\n",
    "    print(f\"Warning: {len(negative)} negative values found!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e9f0",
   "metadata": {},
   "source": [
    "## Step 4: Flow Duration Curve\n",
    "\n",
    "A **flow duration curve (FDC)** is one of the most valuable tools in hydrology. It shows the percentage of time a given discharge is equaled or exceeded.\n",
    "\n",
    "### Why Flow Duration Curves Matter\n",
    "\n",
    "| Application | What the FDC Tells You |\n",
    "|-------------|------------------------|\n",
    "| **Water supply** | How often can we extract X mÂ³/s? |\n",
    "| **Hydropower** | What flow is available 90% of the time? |\n",
    "| **Environmental flows** | What's the natural low-flow regime? |\n",
    "| **Flood risk** | How often do extreme flows occur? |\n",
    "| **Catchment comparison** | Is this catchment flashy or stable? |\n",
    "\n",
    "### Reading the Curve\n",
    "\n",
    "- **Steep slope** = Flashy catchment (quick response to rainfall, high variability)\n",
    "- **Gentle slope** = Baseflow-dominated (groundwater fed, stable flows)\n",
    "- **Q50** = Median flow (exceeded 50% of the time)\n",
    "- **Q90** = Low flow indicator (exceeded 90% of the time)\n",
    "- **Q10** = High flow indicator (exceeded only 10% of the time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tyehmspewg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE FLOW DURATION CURVE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Creating Flow Duration Curve...\")\n",
    "\n",
    "# Get discharge values (excluding NaN)\n",
    "Q = df[DISCHARGE_COLUMN].dropna()\n",
    "\n",
    "# Sort discharge values from highest to lowest\n",
    "sorted_q = np.sort(Q)[::-1]\n",
    "\n",
    "# Calculate exceedance probability for each value\n",
    "# Exceedance probability = rank / (n + 1) * 100\n",
    "n = len(sorted_q)\n",
    "exceedance_prob = np.arange(1, n + 1) / (n + 1) * 100\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the flow duration curve\n",
    "ax.plot(exceedance_prob, sorted_q, 'b-', linewidth=1.5)\n",
    "\n",
    "# Add reference lines for key percentiles\n",
    "q10 = np.percentile(Q, 90)  # Flow exceeded 10% of time\n",
    "q50 = np.percentile(Q, 50)  # Median flow\n",
    "q90 = np.percentile(Q, 10)  # Flow exceeded 90% of time\n",
    "\n",
    "ax.axhline(y=q10, color='orange', linestyle='--', alpha=0.7, label=f'Q10 = {q10:.1f} mÂ³/s')\n",
    "ax.axhline(y=q50, color='green', linestyle='--', alpha=0.7, label=f'Q50 = {q50:.1f} mÂ³/s')\n",
    "ax.axhline(y=q90, color='red', linestyle='--', alpha=0.7, label=f'Q90 = {q90:.1f} mÂ³/s')\n",
    "\n",
    "# Add vertical reference lines\n",
    "ax.axvline(x=10, color='orange', linestyle=':', alpha=0.5)\n",
    "ax.axvline(x=50, color='green', linestyle=':', alpha=0.5)\n",
    "ax.axvline(x=90, color='red', linestyle=':', alpha=0.5)\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_xlabel('Exceedance Probability (%)', fontsize=12)\n",
    "ax.set_ylabel('Discharge (mÂ³/s)', fontsize=12)\n",
    "ax.set_title(f'{station_name} - Flow Duration Curve', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Use log scale for y-axis (common for FDCs)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key values\n",
    "print()\n",
    "print(\"KEY FLOW DURATION VALUES\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"  Q10 (exceeded 10% of time):  {q10:>8.1f} mÂ³/s  (high flow)\")\n",
    "print(f\"  Q50 (exceeded 50% of time):  {q50:>8.1f} mÂ³/s  (median)\")\n",
    "print(f\"  Q90 (exceeded 90% of time):  {q90:>8.1f} mÂ³/s  (low flow)\")\n",
    "print()\n",
    "print(f\"  Flow range ratio (Q10/Q90): {q10/q90:.1f}\")\n",
    "print(\"  (Higher ratio = more variable/flashy catchment)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wghemp4mmvi",
   "metadata": {},
   "source": [
    "> **Understanding the Code:**\n",
    "> \n",
    "> 1. **Sort descending**: `np.sort(Q)[::-1]` - Highest flows first\n",
    "> 2. **Calculate exceedance**: Each value's rank divided by total count gives probability\n",
    "> 3. **Log scale**: Y-axis uses logarithmic scale to show low flows clearly\n",
    "> 4. **Q10/Q90 ratio**: A simple metric for flow variability (values >10 indicate flashy catchments)\n",
    ">\n",
    "> This tutorial uses the **exceedance probability convention**: Q10 = flow exceeded 10% of time (high flow), Q90 = flow exceeded 90% of time (low flow).\n",
    "\n",
    "---\n",
    "\n",
    "## Ideas for Further Extension\n",
    "\n",
    "Now that you have a complete analysis workflow, here are ideas to extend it:\n",
    "\n",
    "### Add More Statistics\n",
    "- **Baseflow index**: Ratio of baseflow to total flow\n",
    "- **Flashiness index**: How quickly flow changes from day to day\n",
    "- **7-day low flow (7Q10)**: Important for water quality permits\n",
    "- **Annual maxima series**: For flood frequency analysis\n",
    "\n",
    "### Improve Visualizations\n",
    "- Add a **rolling mean** (e.g., 30-day) to smooth the hydrograph\n",
    "- Create **annual hydrographs** overlaid for comparison\n",
    "- Add **precipitation data** as a secondary y-axis\n",
    "- Export plots with your organization's branding\n",
    "\n",
    "### Automate for Multiple Stations\n",
    "- Loop through all CSV files in your data folder\n",
    "- Generate a summary table comparing stations\n",
    "- Create a multi-panel figure with all stations\n",
    "\n",
    "### Connect to Your Workflow\n",
    "- **Export to Excel**: `df.to_excel('results.xlsx')` for reports\n",
    "- **Save statistics to JSON**: For automated reporting pipelines\n",
    "- **Create a reusable function**: Package your analysis as a module\n",
    "\n",
    "### Example: Multi-Station Loop\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "# Process all CAMELS files\n",
    "for csv_file in DATA_PATH.glob('camels_*.csv'):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # ... run your analysis ...\n",
    "    print(f\"Processed: {csv_file.name}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9f0a1",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### \"FileNotFoundError: camels_XXXXX_discharge.csv\"\n",
    "\n",
    "- Make sure you completed Module 4a and downloaded the data\n",
    "- Check you're in the correct project folder\n",
    "- Verify the file exists in the `data/` folder\n",
    "- Update `STATION_ID` to match your downloaded file\n",
    "\n",
    "### \"KeyError: 'discharge_m3s'\"\n",
    "\n",
    "- The column name doesn't match your data\n",
    "- Check your CSV headers: `print(df.columns)`\n",
    "- Update `DISCHARGE_COLUMN` to match\n",
    "\n",
    "### Plot looks empty or wrong\n",
    "\n",
    "- Check that dates were parsed correctly: `print(df.index)`\n",
    "- Verify data range: `print(df[DISCHARGE_COLUMN].describe())`\n",
    "- Look for all-NaN data in specific periods\n",
    "\n",
    "### \"SettingWithCopyWarning\"\n",
    "\n",
    "This warning can be ignored for nowâ€”it doesn't affect your results. It's about pandas' internal data handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0a1b2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, you:\n",
    "\n",
    "âœ… Loaded and prepared time series data with pandas  \n",
    "âœ… Calculated key hydrological statistics  \n",
    "âœ… Identified extreme flow events  \n",
    "âœ… Created professional visualizations (hydrograph + monthly boxplots)  \n",
    "âœ… Built a flow duration curve with key percentiles  \n",
    "âœ… Learned how to adapt the script for your own data  \n",
    "\n",
    "### What You've Built\n",
    "\n",
    "You now have a reusable discharge analysis workflow:\n",
    "\n",
    "```\n",
    "Input: CSV with discharge data\n",
    "    â†“\n",
    "Process: Python script\n",
    "    â†“\n",
    "Output: Statistics + Hydrograph + Monthly plots + Flow Duration Curve\n",
    "```\n",
    "\n",
    "This same pattern applies to most water modelling tasksâ€”load data, process it, visualize results.\n",
    "\n",
    "---\n",
    "\n",
    "**Next up:** Explore additional resources and next steps â†’ [Module 5: Resources & Next Steps](05_resources_next_steps.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-for-water-modellers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
