{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Module 4a: Getting Hydrological Data\n",
    "## Finding and Accessing Open Streamflow Data\n",
    "\n",
    "**Time required:** 25-30 minutes  \n",
    "**Prerequisites:** Module 3a (Python basics), Module 3b (AI assistance)  \n",
    "**What you'll learn:** How to find and download hydrological data programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## The Data Challenge\n",
    "\n",
    "Ask any hydrologist about their biggest challenge, and you'll often hear: **\"Getting the data.\"**\n",
    "\n",
    "Before you can analyze discharge patterns, calibrate a model, or validate flood predictions, you need data. And getting that data is often harder than the analysis itself.\n",
    "\n",
    "### Why Is It So Difficult?\n",
    "\n",
    "| Challenge | Example |\n",
    "|-----------|--------|\n",
    "| **Different formats** | CSV, Excel, XML, proprietary formats, PDF tables |\n",
    "| **Different sources** | National agencies, research institutions, utilities |\n",
    "| **Access restrictions** | Some data requires registration, payment, or formal requests |\n",
    "| **Quality variations** | Gaps, errors, different QA procedures |\n",
    "| **Different conventions** | Date formats, time zones, units (mÂ³/s vs. L/s vs. cfs) |\n",
    "| **Documentation gaps** | Missing metadata about station location, catchment area |\n",
    "\n",
    "### The Good News\n",
    "\n",
    "The hydrological community has been working to make data more accessible. Several **large-scale, open datasets** now exist that provide:\n",
    "\n",
    "- Standardized formats\n",
    "- Consistent quality control\n",
    "- Rich metadata (catchment attributes)\n",
    "- Easy programmatic access\n",
    "\n",
    "In this module, we'll explore these resources and learn how to access them with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## Open Hydrological Data Sources\n",
    "\n",
    "### Global and Continental Datasets\n",
    "\n",
    "**[Caravan](https://github.com/kratzert/Caravan)** ðŸŒ  \n",
    "A global collection of meteorological and hydrological data for large-sample hydrology. Combines data from multiple CAMELS datasets worldwide.\n",
    "- 6,830+ catchments globally\n",
    "- Daily streamflow + meteorological forcing\n",
    "- 65+ catchment attributes\n",
    "- Citation: Kratzert et al. (2023)\n",
    "\n",
    "**[GRDC (Global Runoff Data Centre)](https://www.bafg.de/GRDC/)**  \n",
    "The world's largest archive of river discharge data.\n",
    "- 10,000+ stations worldwide\n",
    "- Long historical records (some > 100 years)\n",
    "- Requires registration for access\n",
    "\n",
    "**[GloFAS](https://www.globalfloods.eu/)** (Global Flood Awareness System)  \n",
    "Real-time and historical flood forecasting data from ECMWF/Copernicus.\n",
    "\n",
    "### The CAMELS Family\n",
    "\n",
    "CAMELS (**C**atchment **A**ttributes and **ME**teorology for **L**arge-sample **S**tudies) is a family of datasets designed for hydrological research. Each regional dataset follows similar standards:\n",
    "\n",
    "| Dataset | Region | Catchments | Reference |\n",
    "|---------|--------|------------|----------|\n",
    "| **CAMELS** | USA | 671 | Newman et al. (2015) |\n",
    "| **CAMELS-CL** | Chile | 516 | Alvarez-Garreton et al. (2018) |\n",
    "| **CAMELS-BR** | Brazil | 897 | Chagas et al. (2020) |\n",
    "| **CAMELS-GB** | Great Britain | 671 | Coxon et al. (2020) |\n",
    "| **CAMELS-AUS** | Australia | 222 | Fowler et al. (2021) |\n",
    "| **CAMELS-CH** | Switzerland | 331 | HÃ¶ge et al. (2023) |\n",
    "| **LamaH-CE** | Central Europe | 859 | Klingler et al. (2021) |\n",
    "\n",
    "> **Why CAMELS matters:**  \n",
    "> These datasets include not just streamflow, but also catchment characteristics (area, elevation, geology, land use) and meteorological forcing. This makes them ideal for testing models, machine learning, and comparative hydrology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## Practical: Accessing CAMELS Data with Python\n",
    "\n",
    "We'll use **PyGeoHydro**, a Python package that provides easy access to various hydrological datasets, including CAMELS-US.\n",
    "\n",
    "### Step 1: Install PyGeoHydro\n",
    "\n",
    "In your project folder, add the package:\n",
    "\n",
    "```bash\n",
    "uv add pygeohydro\n",
    "```\n",
    "\n",
    "This may take a moment as it installs PyGeoHydro and its dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8",
   "metadata": {},
   "source": [
    "### Step 2: Explore Available Stations\n",
    "\n",
    "Run the following code to see what's available in the CAMELS dataset. You can run it directly here in the notebook, or save it as `explore_camels.py` to run from the terminal with `uv run explore_camels.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CAMELS dataset information...\n",
      "\n",
      "Number of stations: 671\n",
      "\n",
      "Available attributes (first 20):\n",
      "  huc_02\n",
      "  gauge_name\n",
      "  q_mean\n",
      "  runoff_ratio\n",
      "  slope_fdc\n",
      "  baseflow_index\n",
      "  stream_elas\n",
      "  q5\n",
      "  q95\n",
      "  high_q_freq\n",
      "  high_q_dur\n",
      "  low_q_freq\n",
      "  low_q_dur\n",
      "  zero_q_freq\n",
      "  hfd_mean\n",
      "  soil_depth_pelletier\n",
      "  soil_depth_statsgo\n",
      "  soil_porosity\n",
      "  soil_conductivity\n",
      "  max_water_content\n",
      "  ... and 41 more\n",
      "\n",
      "Sample stations:\n",
      "                                                 gauge_name    q_mean\n",
      "gauge_id                                                             \n",
      "01013500                   Fish River Near Fort Kent, Maine  1.699155\n",
      "01022500            Narraguagus River At Cherryfield, Maine  2.173062\n",
      "01030500        Mattawamkeag River Near Mattawamkeag, Maine  1.820108\n",
      "01031500       Piscataquis River Near Dover-Foxcroft, Maine  2.030242\n",
      "01047000         Carrabassett River Near North Anson, Maine  2.182870\n",
      "01052500          Diamond River Near Wentworth Location, NH  2.405105\n",
      "01054200                        Wild River At Gilead, Maine  2.731742\n",
      "01055000                    Swift River Near Roxbury, Maine  2.279897\n",
      "01057000  Little Androscoggin River Near South Paris, Maine  1.823551\n",
      "01073000                       Oyster River Near Durham, NH  1.703194\n",
      "Number of stations: 671\n",
      "\n",
      "Available attributes (first 20):\n",
      "  huc_02\n",
      "  gauge_name\n",
      "  q_mean\n",
      "  runoff_ratio\n",
      "  slope_fdc\n",
      "  baseflow_index\n",
      "  stream_elas\n",
      "  q5\n",
      "  q95\n",
      "  high_q_freq\n",
      "  high_q_dur\n",
      "  low_q_freq\n",
      "  low_q_dur\n",
      "  zero_q_freq\n",
      "  hfd_mean\n",
      "  soil_depth_pelletier\n",
      "  soil_depth_statsgo\n",
      "  soil_porosity\n",
      "  soil_conductivity\n",
      "  max_water_content\n",
      "  ... and 41 more\n",
      "\n",
      "Sample stations:\n",
      "                                                 gauge_name    q_mean\n",
      "gauge_id                                                             \n",
      "01013500                   Fish River Near Fort Kent, Maine  1.699155\n",
      "01022500            Narraguagus River At Cherryfield, Maine  2.173062\n",
      "01030500        Mattawamkeag River Near Mattawamkeag, Maine  1.820108\n",
      "01031500       Piscataquis River Near Dover-Foxcroft, Maine  2.030242\n",
      "01047000         Carrabassett River Near North Anson, Maine  2.182870\n",
      "01052500          Diamond River Near Wentworth Location, NH  2.405105\n",
      "01054200                        Wild River At Gilead, Maine  2.731742\n",
      "01055000                    Swift River Near Roxbury, Maine  2.279897\n",
      "01057000  Little Androscoggin River Near South Paris, Maine  1.823551\n",
      "01073000                       Oyster River Near Durham, NH  1.703194\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Explore CAMELS dataset stations.\"\"\"\n",
    "\n",
    "import pygeohydro as gh\n",
    "\n",
    "print(\"Loading CAMELS dataset information...\")\n",
    "print()\n",
    "\n",
    "# Get CAMELS dataset (returns tuple: attributes DataFrame, streamflow Dataset)\n",
    "camels_attrs, camels_qobs = gh.get_camels()\n",
    "\n",
    "# Show available information\n",
    "print(f\"Number of stations: {len(camels_attrs)}\")\n",
    "print()\n",
    "\n",
    "# Show some columns available\n",
    "print(\"Available attributes (first 20):\")\n",
    "for i, col in enumerate(camels_attrs.columns[:20]):\n",
    "    print(f\"  {col}\")\n",
    "print(f\"  ... and {len(camels_attrs.columns) - 20} more\")\n",
    "print()\n",
    "\n",
    "# Show sample of station names\n",
    "print(\"Sample stations:\")\n",
    "print(camels_attrs[['gauge_name', 'q_mean']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "You should see:\n",
    "- 671 stations available\n",
    "- Many catchment attributes (area, precipitation, geology, etc.)\n",
    "- Station names and basic information\n",
    "\n",
    "> **First run:** The first time you run this, PyGeoHydro will download the CAMELS dataset (~140 MB). This is cached locally for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "### Step 3: Select a Station\n",
    "\n",
    "Let's find a station with interesting characteristics. The code below filters for medium-sized catchments with reasonable runoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding stations with specific characteristics...\n",
      "\n",
      "Stations matching criteria: 225\n",
      "\n",
      "Top 10 stations by mean runoff:\n",
      "\n",
      "  Station ID: 12041200\n",
      "  Name: Hoh River At Us Highway 101 Near Forks, WA\n",
      "  Area: 656 kmÂ²\n",
      "  Mean runoff: 9.59 mm/day\n",
      "\n",
      "  Station ID: 12056500\n",
      "  Name: Nf Skokomish R Bl Staircase Rpds Nr Hoodsport, WA\n",
      "  Area: 147 kmÂ²\n",
      "  Mean runoff: 8.70 mm/day\n",
      "\n",
      "  Station ID: 12147500\n",
      "  Name: North Fork Tolt River Near Carnation, WA\n",
      "  Area: 103 kmÂ²\n",
      "  Mean runoff: 8.30 mm/day\n",
      "\n",
      "  Station ID: 12043000\n",
      "  Name: Calawah River Near Forks, WA\n",
      "  Area: 337 kmÂ²\n",
      "  Mean runoff: 7.82 mm/day\n",
      "\n",
      "  Station ID: 14400000\n",
      "  Name: Chetco River Near Brookings, OR\n",
      "  Area: 703 kmÂ²\n",
      "  Mean runoff: 7.57 mm/day\n",
      "\n",
      "  Station ID: 12141300\n",
      "  Name: Middle Fork Snoqualmie River Near Tanner, WA\n",
      "  Area: 402 kmÂ²\n",
      "  Mean runoff: 7.50 mm/day\n",
      "\n",
      "  Station ID: 12010000\n",
      "  Name: Naselle River Near Naselle, WA\n",
      "  Area: 142 kmÂ²\n",
      "  Mean runoff: 7.20 mm/day\n",
      "\n",
      "  Station ID: 12167000\n",
      "  Name: Nf Stillaguamish River Near Arlington, WA\n",
      "  Area: 684 kmÂ²\n",
      "  Mean runoff: 6.82 mm/day\n",
      "\n",
      "  Station ID: 12186000\n",
      "  Name: Sauk River Ab Whitechuck River Near Darrington, WA\n",
      "  Area: 398 kmÂ²\n",
      "  Mean runoff: 6.77 mm/day\n",
      "\n",
      "  Station ID: 12035000\n",
      "  Name: Satsop River Near Satsop, WA\n",
      "  Area: 770 kmÂ²\n",
      "  Mean runoff: 6.75 mm/day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Select a CAMELS station based on criteria.\"\"\"\n",
    "\n",
    "import pygeohydro as gh\n",
    "\n",
    "# Get CAMELS data\n",
    "camels_attrs, camels_qobs = gh.get_camels()\n",
    "\n",
    "print(\"Finding stations with specific characteristics...\")\n",
    "print()\n",
    "\n",
    "# Filter for medium-sized catchments with good data\n",
    "# area_gages2: catchment area in kmÂ²\n",
    "# q_mean: mean daily discharge in mm/day\n",
    "selected = camels_attrs[\n",
    "    (camels_attrs['area_gages2'] > 100) &      # At least 100 kmÂ²\n",
    "    (camels_attrs['area_gages2'] < 1000) &     # Not too large\n",
    "    (camels_attrs['q_mean'] > 1.0)             # Reasonable runoff\n",
    "].copy()\n",
    "\n",
    "print(f\"Stations matching criteria: {len(selected)}\")\n",
    "print()\n",
    "\n",
    "# Show top 10 by mean discharge\n",
    "top_stations = selected.nlargest(10, 'q_mean')\n",
    "print(\"Top 10 stations by mean runoff:\")\n",
    "print()\n",
    "\n",
    "for idx, row in top_stations.iterrows():\n",
    "    print(f\"  Station ID: {idx}\")\n",
    "    print(f\"  Name: {row['gauge_name']}\")\n",
    "    print(f\"  Area: {row['area_gages2']:.0f} kmÂ²\")\n",
    "    print(f\"  Mean runoff: {row['q_mean']:.2f} mm/day\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "Note down a station ID that looks interestingâ€”we'll download its data next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "### Step 4: Download Streamflow Data\n",
    "\n",
    "Now let's download actual streamflow data for a selected station. Change `STATION_ID` to the station you chose, or use the default example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for station: 01013500\n",
      "\n",
      "Station: Fish River Near Fort Kent, Maine\n",
      "Area: 2253 kmÂ²\n",
      "Mean elevation: 250 m\n",
      "\n",
      "Extracting streamflow data...\n",
      "Retrieved 12784 daily values\n",
      "Period: 1980-01-01 to 2014-12-31\n",
      "Missing values: 92\n",
      "\n",
      "Basic statistics (mÂ³/s):\n",
      "  Mean:   43.76\n",
      "  Min:    1.19\n",
      "  Max:    506.87\n",
      "\n",
      "Station: Fish River Near Fort Kent, Maine\n",
      "Area: 2253 kmÂ²\n",
      "Mean elevation: 250 m\n",
      "\n",
      "Extracting streamflow data...\n",
      "Retrieved 12784 daily values\n",
      "Period: 1980-01-01 to 2014-12-31\n",
      "Missing values: 92\n",
      "\n",
      "Basic statistics (mÂ³/s):\n",
      "  Mean:   43.76\n",
      "  Min:    1.19\n",
      "  Max:    506.87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Download streamflow data from CAMELS.\"\"\"\n",
    "\n",
    "import pygeohydro as gh\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration - change this to your chosen station\n",
    "STATION_ID = \"01013500\"  # Example: Fish River near Fort Kent, Maine\n",
    "\n",
    "print(f\"Downloading data for station: {STATION_ID}\")\n",
    "print()\n",
    "\n",
    "# Get CAMELS data (attributes and streamflow)\n",
    "camels_attrs, camels_qobs = gh.get_camels()\n",
    "\n",
    "if STATION_ID not in camels_attrs.index:\n",
    "    print(f\"Error: Station {STATION_ID} not found in CAMELS dataset.\")\n",
    "    print(\"Check the station ID and try again.\")\n",
    "else:\n",
    "    station_info = camels_attrs.loc[STATION_ID]\n",
    "    area_km2 = station_info['area_gages2']\n",
    "    print(f\"Station: {station_info['gauge_name']}\")\n",
    "    print(f\"Area: {area_km2:.0f} kmÂ²\")\n",
    "    print(f\"Mean elevation: {station_info['elev_mean']:.0f} m\")\n",
    "    print()\n",
    "    \n",
    "    # Extract streamflow for this station from the xarray Dataset\n",
    "    print(\"Extracting streamflow data...\")\n",
    "    \n",
    "    # Get discharge data - raw CAMELS data is in cfs (cubic feet per second)\n",
    "    Q_cfs = camels_qobs['discharge'].sel(station_id=STATION_ID)\n",
    "    \n",
    "    # Convert to pandas Series\n",
    "    Q_cfs = Q_cfs.to_series()\n",
    "    \n",
    "    # Convert cfs to mÂ³/s (1 cfs = 0.0283168 mÂ³/s)\n",
    "    Q_m3s = Q_cfs * 0.0283168\n",
    "    \n",
    "    # Also calculate mm/day for reference\n",
    "    Q_mm_day = Q_m3s * 86400 / (area_km2 * 1e6) * 1000\n",
    "    \n",
    "    print(f\"Retrieved {len(Q_m3s)} daily values\")\n",
    "    print(f\"Period: {Q_m3s.index.min().strftime('%Y-%m-%d')} to {Q_m3s.index.max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Missing values: {Q_m3s.isna().sum()}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Basic statistics (mÂ³/s):\")\n",
    "    print(f\"  Mean:   {Q_m3s.mean():.2f}\")\n",
    "    print(f\"  Min:    {Q_m3s.min():.2f}\")\n",
    "    print(f\"  Max:    {Q_m3s.max():.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21cf37",
   "metadata": {},
   "source": "### ðŸ“ Understanding File Paths\n\nBefore we save our data, let's understand how Python finds files on your computer.\n\n#### What is a File Path?\n\nA **path** tells Python where to find (or save) a file. There are two types:\n\n**Absolute Path** (Full address from the root of your computer)\n```python\n'/Users/yourname/Documents/project/data/my_data.csv'  # macOS/Linux\n'C:\\\\Users\\\\yourname\\\\Documents\\\\project\\\\data\\\\my_data.csv'  # Windows\n```\n\n**Relative Path** (Address relative to your current location)\n```python\n'../data/my_data.csv'  # Go up one folder, then into data/\n```\n\n#### Our Project Structure\n\n```\npython-for-water-modellers/          â† Project root\nâ”œâ”€â”€ data/                            â† Data folder\nâ”‚   â””â”€â”€ camels_01013500_discharge.csv                  \nâ”œâ”€â”€ tutorials/                       â† We are HERE (this notebook)\nâ”‚   â”œâ”€â”€ 04a_getting_data.ipynb      \nâ”‚   â””â”€â”€ 04b_discharge_analysis.ipynb\n```\n\nWhen running **locally** in VS Code, the notebook runs from `tutorials/`, so we use `../data/` to go up one level.\n\nWhen running in **Binder** (cloud), the working directory is the project root, so we use `data/` directly.\n\n#### Smart Path Resolution\n\nThe code below automatically detects which environment you're in and uses the correct path:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef15a6b",
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\ndef get_data_path():\n    \"\"\"\n    Get the correct path to the data folder.\n    Works both locally (VS Code) and in Binder.\n    \"\"\"\n    # Check if running in Binder (cloud environment)\n    if 'BINDER_REQUEST' in os.environ or 'BINDER_LAUNCH_HOST' in os.environ:\n        # Binder: data is at ~/data/ (repo is cloned to home directory)\n        data_path = Path.home() / 'data'\n    elif Path('../data').exists():\n        # Local: notebook is in tutorials/, data is at ../data/\n        data_path = Path('../data')\n    elif Path('data').exists():\n        # Alternative: already at repo root\n        data_path = Path('data')\n    else:\n        # Fallback\n        data_path = Path('../data')\n    \n    return data_path\n\n# Get the data path for this environment\nDATA_PATH = get_data_path()\nprint(f\"Data path: {DATA_PATH}\")\nprint(f\"Data path exists: {DATA_PATH.exists()}\")"
  },
  {
   "cell_type": "code",
   "id": "clgpzz2vb79",
   "source": "# Save the data using the detected path\noutput_df = pd.DataFrame({\n    'date': Q_m3s.index,\n    'discharge_m3s': Q_m3s.values,\n    'discharge_mm_day': Q_mm_day.values\n})\noutput_df['station_id'] = STATION_ID\noutput_df['station_name'] = station_info['gauge_name']\n\n# Use the DATA_PATH we determined above\noutput_file = DATA_PATH / f'camels_{STATION_ID}_discharge.csv'\noutput_df.to_csv(output_file, index=False)\n\nprint(f\"Data saved to: {output_file}\")\nprint()\nprint(\"You can now use this file in Module 4b for analysis!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "379ef354",
   "metadata": {},
   "source": [
    "### Step 5: Quick Visualization\n",
    "\n",
    "Let's make a quick plot to verify the data looks reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"Quick visualization of downloaded streamflow data.\"\"\"\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the data we just downloaded using DATA_PATH\nINPUT_FILE = DATA_PATH / f'camels_{STATION_ID}_discharge.csv'\n\nprint(f\"Loading: {INPUT_FILE}\")\ndf = pd.read_csv(INPUT_FILE)\ndf['date'] = pd.to_datetime(df['date'])\ndf.set_index('date', inplace=True)\n\nstation_name = df['station_name'].iloc[0]\n\n# Create a simple plot\nfig, ax = plt.subplots(figsize=(12, 5))\n\n# Plot 3 years of data for clarity\ndf_subset = df['2010':'2012']\n\nax.plot(df_subset.index, df_subset['discharge_m3s'], 'b-', linewidth=0.5)\nax.fill_between(df_subset.index, 0, df_subset['discharge_m3s'], alpha=0.3)\n\nax.set_xlabel('Date')\nax.set_ylabel('Discharge (mÂ³/s)')\nax.set_title(f'{station_name}\\nDaily Discharge 2010-2012')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Plot displayed above!\")"
  },
  {
   "cell_type": "markdown",
   "id": "b609bfab",
   "metadata": {},
   "source": [
    "**What you should see:**\n",
    "- A hydrograph showing the seasonal pattern of streamflow\n",
    "- Higher flows in spring (snowmelt) for mountain catchments\n",
    "- Lower flows in late summer/autumn\n",
    "- Individual flood peaks from storm events\n",
    "\n",
    "The plot is saved as `streamflow_preview.png` in your `data/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7a8b9",
   "metadata": {},
   "source": [
    "## For Swiss-Specific Work: CAMELS-CH\n",
    "\n",
    "If you're working specifically with Swiss catchments, you'll want to use **CAMELS-CH**.\n",
    "\n",
    "### What's in CAMELS-CH?\n",
    "\n",
    "- **331 catchments** across Switzerland\n",
    "- Daily streamflow data (1981-2020)\n",
    "- 211 catchment attributes (topography, climate, geology, land cover, hydrology)\n",
    "- Comprehensive metadata\n",
    "\n",
    "### How to Access\n",
    "\n",
    "CAMELS-CH is available from Zenodo:\n",
    "\n",
    "1. Visit: https://doi.org/10.5281/zenodo.8212506\n",
    "2. Download the dataset files\n",
    "3. The data comes as CSV files that you can load with pandas\n",
    "\n",
    "### Example Loading Code\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# After downloading and extracting CAMELS-CH\n",
    "# Load catchment attributes\n",
    "attributes = pd.read_csv('CAMELS_CH_catchment_attributes.csv')\n",
    "\n",
    "# Load streamflow for a specific station\n",
    "streamflow = pd.read_csv('CAMELS_CH_streamflow_daily.csv')\n",
    "\n",
    "# Filter for your station of interest\n",
    "station_id = '2004'  # Example: Aare at Ringgenberg\n",
    "my_data = streamflow[streamflow['station_id'] == station_id]\n",
    "```\n",
    "\n",
    "### Citation\n",
    "\n",
    "When using CAMELS-CH in publications, please cite:\n",
    "\n",
    "> HÃ¶ge, M., Kauzlaric, M., Siber, R., SchÃ¶nenberger, U., Horton, P., Schwanbeck, J., Floriancic, M. G., Viviroli, D., Wilhelm, S., Sikorska-Senoner, A. E., Addor, N., Brunner, M., Pool, S., Zappa, M., & Fenicia, F. (2023). CAMELS-CH: Hydro-meteorological time series and landscape attributes for 331 catchments in hydrologic Switzerland. *Earth System Science Data*, 15, 5755â€“5784."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8b9c0",
   "metadata": {},
   "source": [
    "## Data Quality Considerations\n",
    "\n",
    "Whenever you work with hydrological dataâ€”whether from CAMELS, national databases, or local sourcesâ€”always check:\n",
    "\n",
    "### 1. Missing Values\n",
    "\n",
    "```python\n",
    "# Count missing values\n",
    "missing = df['discharge'].isna().sum()\n",
    "print(f\"Missing: {missing} days ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Where are they?\n",
    "missing_periods = df[df['discharge'].isna()]\n",
    "```\n",
    "\n",
    "### 2. Suspicious Values\n",
    "\n",
    "```python\n",
    "# Check for zeros (often indicate sensor issues)\n",
    "zeros = (df['discharge'] == 0).sum()\n",
    "\n",
    "# Check for negative values (physically impossible)\n",
    "negatives = (df['discharge'] < 0).sum()\n",
    "\n",
    "# Check for extreme spikes (potential errors)\n",
    "mean_q = df['discharge'].mean()\n",
    "std_q = df['discharge'].std()\n",
    "extremes = df[df['discharge'] > mean_q + 5*std_q]\n",
    "```\n",
    "\n",
    "### 3. Time Series Continuity\n",
    "\n",
    "```python\n",
    "# Check for gaps in the time series\n",
    "date_diff = df.index.to_series().diff()\n",
    "gaps = date_diff[date_diff > pd.Timedelta(days=1)]\n",
    "print(f\"Found {len(gaps)} gaps in the time series\")\n",
    "```\n",
    "\n",
    "### 4. Physical Plausibility\n",
    "\n",
    "- Is the catchment area correct?\n",
    "- Do peak flows coincide with precipitation events?\n",
    "- Is the seasonal pattern reasonable for the climate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9c0d1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, you learned:\n",
    "\n",
    "âœ… Why getting hydrological data is challenging  \n",
    "âœ… Key open data sources (CAMELS family, GRDC, Caravan)  \n",
    "âœ… How to access CAMELS data programmatically with PyGeoHydro  \n",
    "âœ… How to explore, select, and download station data  \n",
    "âœ… How to save data for offline analysis  \n",
    "âœ… Where to find CAMELS-CH for Swiss-specific work  \n",
    "âœ… What to check for data quality  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Open datasets exist** â€” You don't always need to process raw data from scratch\n",
    "2. **Python makes access easy** â€” A few lines of code can replace hours of manual downloads\n",
    "3. **Always check quality** â€” Even curated datasets may have issues\n",
    "4. **Save locally** â€” Once you have good data, save it for reproducibility\n",
    "\n",
    "### What You Created\n",
    "\n",
    "By running the code cells in this notebook, you:\n",
    "- Explored available CAMELS stations\n",
    "- Downloaded streamflow data for your chosen station\n",
    "- Created a CSV file: `camels_XXXXX_discharge.csv` in the `data/` folder\n",
    "- Generated a preview plot: `streamflow_preview.png`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Use your downloaded data for a complete analysis â†’ [Module 4b: Your First Water Modelling Script](04b_discharge_analysis.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}